# MCP Memory Server V5 - Environment Configuration
# Copy this file to .env and fill in your actual values
# IMPORTANT: NEVER commit .env to version control!

# ============================================================================
# REQUIRED CONFIGURATION
# ============================================================================

# OpenAI API Key (REQUIRED)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-your-key-here

# PostgreSQL Password (REQUIRED - CHANGE THIS!)
# Generate a strong password: python -c "import secrets; print(secrets.token_urlsafe(32))"
# !!! CRITICAL SECURITY WARNING !!!
# Default value is INSECURE and should NEVER be used in production
POSTGRES_PASSWORD=CHANGE_ME_BEFORE_DEPLOYMENT

# Database Connection String (REQUIRED)
# Format: postgresql://user:password@host:port/database
# UPDATE THIS when you change POSTGRES_PASSWORD!
EVENTS_DB_DSN=postgresql://events:CHANGE_ME_BEFORE_DEPLOYMENT@postgres:5432/events

# ============================================================================
# V5 CONFIGURATION - NEW SIMPLIFIED API
# ============================================================================

# V5 tools: remember(), recall(), forget(), status()
# These tools use new unified collections (content, chunks)
# and content-based ID generation for idempotent storage

# Token Threshold for Event Extraction
# Conversation turns < threshold skip event extraction
# Default: 100
V5_EVENT_EXTRACTION_MIN_TOKENS=100

# Content ID Prefix
# Used for content-based ID generation (art_ + SHA256[:12])
# Default: art_
V5_CONTENT_ID_PREFIX=art_

# ============================================================================
# V4 ENTITY RESOLUTION CONFIGURATION
# ============================================================================

# Embedding Similarity Threshold
# Candidates with similarity >= threshold are sent to LLM for confirmation
# Range: 0.0-1.0 (higher = stricter matching)
# Default: 0.85
ENTITY_SIMILARITY_THRESHOLD=0.85

# Maximum Deduplication Candidates
# Maximum number of candidates to evaluate per entity mention
# Higher values = better accuracy, more LLM calls
# Default: 5
ENTITY_MAX_CANDIDATES=5

# Entity Deduplication Model
# LLM model used for merge/split decisions
# Options: gpt-4o-mini (cheaper), gpt-4o (more accurate)
# Default: gpt-4o-mini
# Cost: ~$0.001 per entity comparison
ENTITY_DEDUP_MODEL=gpt-4o-mini

# ============================================================================
# V5 GRAPH EXPANSION CONFIGURATION (Postgres Joins, No AGE)
# ============================================================================

# Default Graph Budget
# Default number of related items to return when expand=true
# Can be overridden per request
# Default: 10
GRAPH_BUDGET_DEFAULT=10

# Maximum Graph Budget
# Security limit - requests cannot exceed this value
# Prevents resource exhaustion attacks
# Default: 100
GRAPH_BUDGET_MAX=100

# Default Seed Limit
# Default number of primary results to use as expansion seeds
# Default: 5
GRAPH_SEED_LIMIT_DEFAULT=5

# Maximum Seed Limit
# Security limit - requests cannot exceed this value
# Default: 20
GRAPH_SEED_LIMIT_MAX=20

# ============================================================================
# POSTGRESQL CONFIGURATION
# ============================================================================

# PostgreSQL Database Name
POSTGRES_DB=events

# PostgreSQL User
POSTGRES_USER=events

# PostgreSQL Host (Docker internal)
POSTGRES_HOST=postgres

# PostgreSQL Port
POSTGRES_PORT=5432

# Connection Pool Size
# Increase for high-concurrency environments
# Default: 10
PG_POOL_SIZE=10

# Connection Pool Max Overflow
# Additional connections during peak load
# Default: 20
PG_POOL_MAX_OVERFLOW=20

# ============================================================================
# CHROMADB CONFIGURATION
# ============================================================================

# ChromaDB Host (internal Docker network)
CHROMA_HOST=chroma

# ChromaDB Port (internal container port)
CHROMA_PORT=8000

# ============================================================================
# OPENAI MODELS CONFIGURATION
# ============================================================================

# Embedding Model
# Options: text-embedding-3-small, text-embedding-3-large (recommended)
# text-embedding-3-large: 3072 dimensions, best quality
# text-embedding-3-small: 1536 dimensions, faster/cheaper
# Default: text-embedding-3-large
OPENAI_EMBED_MODEL=text-embedding-3-large

# Embedding Dimensions
# Must match the model's output dimensions
# text-embedding-3-large: 3072
# text-embedding-3-small: 1536
OPENAI_EMBED_DIMS=3072

# Event Extraction Model
# Options: gpt-4o-mini (cheaper), gpt-4-turbo-preview, gpt-4o (best quality)
# Default: gpt-4o-mini
# Recommendation: gpt-4o-mini for dev, gpt-4o for production
OPENAI_EVENT_MODEL=gpt-4o-mini

# OpenAI Request Timeout (seconds)
# Default: 30
OPENAI_TIMEOUT=30

# OpenAI Max Retries
# Default: 3
OPENAI_MAX_RETRIES=3

# ============================================================================
# MCP SERVER CONFIGURATION
# ============================================================================

# MCP Server Port
MCP_PORT=3000

# Environment
# Options: development, staging, production
# Default: development
ENVIRONMENT=development

# Log Level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
# Use DEBUG for development, INFO for production
LOG_LEVEL=INFO

# ============================================================================
# EVENT WORKER CONFIGURATION
# ============================================================================

# Worker Identifier
# Use unique IDs if running multiple workers
WORKER_ID=worker-1

# Polling Interval (milliseconds)
# How often the worker checks for new jobs
# Default: 1000 (1 second)
# Recommendation: 1000-5000 for production
POLL_INTERVAL_MS=1000

# Maximum Retry Attempts
# How many times to retry failed extraction jobs
# Default: 5
EVENT_MAX_ATTEMPTS=5

# ============================================================================
# V5 WORKER CONFIGURATION
# ============================================================================
# Note: graph_upsert is disabled in V5 - graph expansion uses Postgres joins

# ============================================================================
# MONITORING CONFIGURATION (Optional)
# ============================================================================

# Enable Prometheus Metrics
# Default: true
METRICS_ENABLED=true

# Metrics Port
# Default: 9090
METRICS_PORT=9090

# Enable Structured JSON Logging
# Default: true
JSON_LOGGING=true

# ============================================================================
# RATE LIMITING (Optional)
# ============================================================================

# Entity Resolution Rate Limit (per minute)
# Maximum entity resolutions per minute
# Default: 100
ENTITY_RATE_LIMIT_PER_MIN=100

# LLM Rate Limit (per minute)
# Maximum LLM calls for entity deduplication per minute
# Default: 60
LLM_RATE_LIMIT_PER_MIN=60

# ============================================================================
# DOCKER COMPOSE CONFIGURATION
# ============================================================================

# Docker Compose Project Name (optional)
# Prefix for all container names
COMPOSE_PROJECT_NAME=mcp-memory-v5

# ============================================================================
# PRODUCTION CHECKLIST
# ============================================================================
#
# Before deploying V5 to production:
#
# 1. [ ] Change POSTGRES_PASSWORD to a strong password
# 2. [ ] Update EVENTS_DB_DSN with the new password
# 3. [ ] Run all migrations (001-009) successfully
# 4. [ ] Test V5 tools: remember, recall, forget, status
# 5. [ ] Verify content deduplication works (same content = same ID)
# 6. [ ] Set OPENAI_EVENT_MODEL=gpt-4o for best quality (optional)
# 7. [ ] Set LOG_LEVEL=INFO
# 8. [ ] Review GRAPH_BUDGET_MAX and GRAPH_SEED_LIMIT_MAX
# 9. [ ] Set up monitoring for new V5 collections (content, chunks)
# 10.[ ] Test rollback procedure on staging
# 11.[ ] Verify graph expansion works via Postgres joins (no AGE)
#
# ============================================================================

# ============================================================================
# DEVELOPMENT CONFIGURATION
# ============================================================================
#
# For development, uncomment these lines:
#
# LOG_LEVEL=DEBUG
# ENVIRONMENT=development
# ENTITY_DEDUP_MODEL=gpt-4o-mini
# POLL_INTERVAL_MS=2000
# V5_EVENT_EXTRACTION_MIN_TOKENS=50
#
# ============================================================================
